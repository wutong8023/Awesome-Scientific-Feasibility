% Example: modify keywords by the way you like.
% Note: the keywords should be predefined in scripts/bibtext_to_md.py # fined_taxonomy
% ---------------- Preprint ----------------
@inproceedings{PradeepMNL21,
  author       = {Ronak Pradeep and
                  Xueguang Ma and
                  Rodrigo Frassetto Nogueira and
                  Jimmy Lin},
  title        = {Scientific Claim Verification with VerT5erini},
  booktitle    = {Proceedings of LOUHI@EACL},
  pages        = {94--103},
  year         = {2021},
  url          = {https://www.aclweb.org/anthology/2021.louhi-1.11/},
  keywords = {
        Method, Resource,
        Biomedical,
        Others RQs,
        T5,
        Other Data Format,
    },
}
@String(PradeepMNL21="We propose a system called VerT5erini that exploits T5 for abstract retrieval, sentence selection, and label prediction, which are three critical sub-tasks of claim verification. We evaluate our pipeline on SciFACT, a newly curated dataset that requires models to not just predict the veracity of claims but also provide relevant sentences from a corpus of scientific literature that support the prediction. ")


@inproceedings{WaddenLLWZCH20,
  author       = {David Wadden and
                  Shanchuan Lin and
                  Kyle Lo and
                  Lucy Lu Wang and
                  Madeleine van Zuylen and
                  Arman Cohan and
                  Hannaneh Hajishirzi},
  title        = {Fact or Fiction: Verifying Scientific Claims},
  booktitle    = {Proceedings of EMNLP},
  pages        = {7534--7550},
  year         = {2020},
  url          = {https://doi.org/10.18653/v1/2020.emnlp-main.609},
  keywords = {
        Method,
        Other Area,
        Others RQs,
        Other Model,
        Other Data Format
    },
}
@String(WaddenLLWZCH20="We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. ")

@inproceedings{WaddenLWCBH22,
  author       = {David Wadden and
                  Kyle Lo and
                  Lucy Lu Wang and
                  Arman Cohan and
                  Iz Beltagy and
                  Hannaneh Hajishirzi},
  title        = {MultiVerS: Improving scientific claim verification with weak supervision
                  and full-document context},
  booktitle    = {Findings of NAACL},
  pages        = {61--76},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-naacl.6},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(WaddenLWCBH22="We introduce MultiVerS, a weakly supervised model for scientific claim verification that leverages full-document context. We show that MultiVerS outperforms strong supervised baselines on the SciFact dataset, achieving state-of-the-art performance on this task. ")

@article{abs-2107-08188,
  author       = {David Wadden and
                  Kyle Lo},
  title        = {Overview and Insights from the SciVer Shared Task on Scientific Claim
                  Verification},
  journal      = {CoRR},
  volume       = {abs/2107.08188},
  year         = {2021},
  url          = {https://arxiv.org/abs/2107.08188},
    keywords = {
            Survey,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2107-08188="We present an overview of the SciVer shared task on scientific claim verification, which was held as part of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP). The shared task aimed to promote research on scientific claim verification, a new task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. ")

@inproceedings{VladikaM23,
  author       = {Juraj Vladika and
                  Florian Matthes},
  title        = {Scientific Fact-Checking: {A} Survey of Resources and Approaches},
  booktitle    = {Findings of ACL},
  pages        = {6215--6230},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.findings-acl.387},
    keywords = {
            Survey,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(VladikaM23="We present a survey of resources and approaches for scientific fact-checking, a task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. ")

@inproceedings{ZhangLFY21,
  author       = {Zhiwei Zhang and
                  Jiyi Li and
                  Fumiyo Fukumoto and
                  Yanming Ye},
  title        = {Abstract, Rationale, Stance: {A} Joint Model for Scientific Claim
                  Verification},
  booktitle    = {Proceedings of EMNLP},
  pages        = {3580--3586},
  year         = {2021},
  url          = {https://doi.org/10.18653/v1/2021.emnlp-main.290},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(ZhangLFY21="We propose a joint model for scientific claim verification that predicts the stance of a given scientific claim by jointly learning to predict the abstract and rationale that support the stance. ")

@inproceedings{WaddenLKCBWH22,
  author       = {David Wadden and
                  Kyle Lo and
                  Bailey Kuehl and
                  Arman Cohan and
                  Iz Beltagy and
                  Lucy Lu Wang and
                  Hannaneh Hajishirzi},
  title        = {SciFact-Open: Towards open-domain scientific claim verification},
  booktitle    = {Findings of EMNLP},
  pages        = {4719--4734},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-emnlp.347},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(WaddenLKCBWH22="Moving to this open-domain evaluation setting, however, poses unique challenges; in particular, it is infeasible to exhaustively annotate all evidence documents. In this work, we present SciFact-Open, a new test collection designed to evaluate the performance of scientific claim verification systems on a corpus of 500K research abstracts. ")

@article{abs-2202-02646,
  author       = {Ashish Rana and
                  Deepanshu Khanna and
                  Muskaan Singh and
                  Tirthankar Ghosal and
                  Harpreet Singh and
                  Prashant Singh Rana},
  title        = {RerrFact: Reduced Evidence Retrieval Representations for Scientific
                  Claim Verification},
  journal      = {CoRR},
  volume       = {abs/2202.02646},
  year         = {2022},
  url          = {https://arxiv.org/abs/2202.02646},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2202-02646="We propose a reduced evidence retrieval model for scientific claim verification that uses a small number of retrieved abstracts to make predictions. ")

@article{abs-2104-11572,
  author       = {Xia Zeng and
                  Arkaitz Zubiaga},
  title        = {{QMUL-SDS} at {SCIVER:} Step-by-Step Binary Classification for Scientific
                  Claim Verification},
  journal      = {CoRR},
  volume       = {abs/2104.11572},
  year         = {2021},
  url          = {https://arxiv.org/abs/2104.11572},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2104-11572="We present a step-by-step binary classification model for scientific claim verification that predicts the stance of a given scientific claim by learning to predict the abstract and rationale that support the stance. ")


@inproceedings{abs-2402-02844,
  author       = {Juraj Vladika and
                  Florian Matthes},
  title        = {Comparing Knowledge Sources for Open-Domain Scientific Claim Verification},
  booktitle    = {Proceedings of EACL},
  pages        = {4719--4734},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.02844},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2402-02844="We compare knowledge sources for open-domain scientific claim verification, a task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. ")

@inproceedings{0001WLKCAW22,
  author       = {Dustin Wright and
                  David Wadden and
                  Kyle Lo and
                  Bailey Kuehl and
                  Arman Cohan and
                  Isabelle Augenstein and
                  Lucy Lu Wang},
  title        = {Generating Scientific Claims for Zero-Shot Scientific Fact Checking},
  booktitle    = {Proceedings of ACL},
  pages        = {2448--2460},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.acl-long.175},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}

@inproceedings{WangS23a,
  author       = {Haoran Wang and
                  Kai Shu},
  title        = {Explainable Claim Verification via Knowledge-Grounded Reasoning with
                  Large Language Models},
  booktitle    = {Findings of EMNLP},
  pages        = {6288--6304},
  year         = {2023},
  url          = {https://aclanthology.org/2023.findings-emnlp.416},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(WangS23a="We propose a knowledge-grounded reasoning model for scientific claim verification that uses large language models to generate explanations for the predictions. ")

@article{abs-2310-09754,
  author       = {Huanhuan Ma and
                  Weizhi Xu and
                  Yifan Wei and
                  Liuji Chen and
                  Liang Wang and
                  Qiang Liu and
                  Shu Wu and
                  Liang Wang},
  title        = {{EX-FEVER:} {A} Dataset for Multi-hop Explainable Fact Verification},
  journal      = {CoRR},
  volume       = {abs/2310.09754},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.09754},
    keywords = {
            Resource,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2310-09754="We present EX-FEVER, a new dataset for multi-hop explainable fact verification. EX-FEVER contains 10,000 claims and 100,000 abstracts from the research literature, and requires models to select abstracts containing evidence that SUPPORTS or REFUTES a given scientific claim. ")

@inproceedings{LuPLNK23,
  author       = {Xinyuan Lu and
                  Liangming Pan and
                  Qian Liu and
                  Preslav Nakov and
                  Min{-}Yen Kan},
  title        = {{SCITAB:} {A} Challenging Benchmark for Compositional Reasoning and
                  Claim Verification on Scientific Tables},
  booktitle    = {Proceedings of EMNLP},
  pages        = {7787--7813},
  year         = {2023},
  url          = {https://aclanthology.org/2023.emnlp-main.483},
    keywords = {
            Resource,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(LuPLNK23="We present SCITAB, a new benchmark for compositional reasoning and claim verification on scientific tables. SCITAB contains 10,000 claims and 100,000 tables from the research literature, and requires models to select tables containing evidence that SUPPORTS or REFUTES a given scientific claim. ")

@article{abs-2305-11859,
  author       = {Jifan Chen and
                  Grace Kim and
                  Aniruddh Sriram and
                  Greg Durrett and
                  Eunsol Choi},
  title        = {Complex Claim Verification with Evidence Retrieved in the Wild},
  journal      = {CoRR},
  volume       = {abs/2305.11859},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.11859},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2305-11859="In this work, we present the first fully automated pipeline to check real-world claims by retrieving raw evidence from the web. We restrict our retriever to only search documents available prior to the claim's making, modeling the realistic scenario where an emerging claim needs to be checked. Our pipeline includes five components: claim decomposition, raw document retrieval, fine-grained evidence retrieval, claim-focused summarization, and veracity judgment.")

@inproceedings{HuHGWY23,
  author       = {Xuming Hu and
                  Zhaochen Hong and
                  Zhijiang Guo and
                  Lijie Wen and
                  Philip S. Yu},
  title        = {Read it Twice: Towards Faithfully Interpretable Fact Verification
                  by Revisiting Evidence},
  booktitle    = {Proceedings of SIGIR},
  pages        = {2319--2323},
  year         = {2023},
  url          = {https://doi.org/10.1145/3539618.3592049},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(HuHGWY23="In light of this, we propose a fact verification model named ReRead to retrieve evidence and verify claim that: (1) Train the evidence retriever to obtain interpretable evidence (i.e., faithfulness and plausibility criteria); (2) Train the claim verifier to revisit the evidence retrieved by the optimized evidence retriever to improve the accuracy. ")

@article{abs-2304-02769,
  author       = {Viswanath Chadalapaka and
                  Derek Nguyen and
                  JoonWon Choi and
                  Shaunak Joshi and
                  Mohammad Rostami},
  title        = {Low-Shot Learning for Fictional Claim Verification},
  journal      = {CoRR},
  volume       = {abs/2304.02769},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2304.02769},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2304-02769="We propose a low-shot learning model for fictional claim verification that uses a small number of examples to make predictions. ")

@inproceedings{MaGJW19,
  author       = {Jing Ma and
                  Wei Gao and
                  Shafiq R. Joty and
                  Kam{-}Fai Wong},
  title        = {Sentence-Level Evidence Embedding for Claim Verification with Hierarchical
                  Attention Networks},
  booktitle    = {Proceedings of ACL},
  pages        = {2561--2571},
  publisher    = {Association for Computational Linguistics},
  year         = {2019},
  url          = {https://doi.org/10.18653/v1/p19-1244},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(MaGJW19="We propose a hierarchical attention network for scientific claim verification that uses sentence-level evidence embeddings to make predictions. ")

@article{abs-2301-08914,
  author       = {Sai Gurrapu and
                  Lifu Huang and
                  Feras A. Batarseh},
  title        = {ExClaim: Explainable Neural Claim Verification Using Rationalization},
  journal      = {CoRR},
  volume       = {abs/2301.08914},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2301.08914},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(abs-2301-08914="We propose an explainable neural claim verification model that uses rationalization to generate explanations for the predictions. ")

@inproceedings{YaoS0CH23,
  author       = {Barry Menglong Yao and
                  Aditya Shah and
                  Lichao Sun and
                  Jin{-}Hee Cho and
                  Lifu Huang},
  title        = {End-to-End Multimodal Fact-Checking and Explanation Generation: {A}
                  Challenging Dataset and Models},
  booktitle    = {Proceedings of SIGIR},
  pages        = {2733--2743},
  year         = {2023},
  url          = {https://doi.org/10.1145/3539618.3591879},
    keywords = {
            Method,
            Other Area,
            Others RQs,
            Other Model,
            Other Data Format
        },
}
@String(YaoS0CH23="We present a challenging dataset and models for end-to-end multimodal fact-checking and explanation generation. ")

@article{9780199734689,
    author = {Holyoak, Keith J. and Morrison, Robert G.},
    title = {Thinking and Reasoning: A Reader's Guide},
    journal = {The Oxford Handbook of Thinking and Reasoning},
    year = {2012},
    url = {https://doi.org/10.1093/oxfordhb/9780199734689.001.0001},
}
@String(9780199734689="This introductory article begins by asking: What is thinking? It looks at the various meanings of the concept in linguistic and philosophical terms. It summarizes the history of the academic study of thinking and reasoning. Finally it gives an outline of the six parts of the book which look in turn at general approaches to thinking and reasoning; inductive, deductive, and abductive reasoning; problem solving, intelligence, and creative thinking; judgment and decision making; ontogeny, phylogeny, language, and culture; and finally modes of thinking.")

@article{kemp2014taxonomy,
  title={A taxonomy of inductive problems},
  author={Kemp, Charles and Jern, Alan},
  journal={Psychonomic bulletin and review},
  volume={21},
  pages={23--46},
  year={2014},
  url = {https://www.charleskemp.com/papers/kempj_ataxonomyofinductiveproblems.pdf},
    keywords = {
                Survey,
                Other Area,
                Inductive Reasoning,
                Other Model,
                Other Data Format
            },
}
@String(kemp2014taxonomy="Inductive inferences about objects, features, categories, and relations have been studied for many years, but thereare few attempts to chart the range of inductive problems that humans are able to solve. We present a taxonomy of inductive problems that helps to clarify the relationships between familiar inductive problems such as generalization, categorization, and identification, and that introduces new inductive problems for psychological investigation. Our taxonomy is founded on the idea that semantic knowledge is organized into systems of objects, features, categories, and relations, and we attempt to characterize all of the inductive problems that can arise when these systems are partially observed. Recent studies have begun to address some of the new problems in our taxonomy, and future work should aim to develop unified theories of inductive reasoning that explain how people solve all of the problems in the taxonomy")

@article{HanRPK24,
  author       = {Simon Jerome Han and
                  Keith J. Ransom and
                  Andrew Perfors and
                  Charles Kemp},
  title        = {Inductive reasoning in humans and large language models},
  journal      = {Cogn. Syst. Res.},
  volume       = {83},
  pages        = {101155},
  year         = {2024},
  url          = {https://doi.org/10.1016/j.cogsys.2023.101155},
    keywords = {
            Method, Resource,
            Other Area,
            Inductive Reasoning,
            ChatGPT,
            Other Data Format
        },
}
@String(HanRPK24="Apply GPT-3.5 and GPT-4 to a classic inductive reasoning task known as property induction. GPT-3.5 struggles to capture many aspects of human behavior. GPT-4â€™s performance qualitatively matches that of humans, aside from the phenomenon of premise non-monotonicity. Provide two large property induction datasets that can serve as future benchmarks.")

@article{lucas2015improved,
  title={An improved probabilistic account of counterfactual reasoning.},
  author={Lucas, Christopher G and Kemp, Charles},
  journal={Psychological review},
  volume={122},
  number={4},
  pages={700},
  year={2015},
  url = {https://psycnet.apa.org/record/2015-45017-003},
    keywords = {
            Method,
            Other Area,
            Counterfactual Reasoning,
            Other Model,
            Other Data Format
        },
}
@String(lucas2015improved="When people want to identify the causes of an event, assign credit or blame, or learn from their mistakes, they often reflect on how things could have gone differently. In this kind of reasoning, one considers a counterfactual world in which some events are different from their real-world counterparts and considers what else would have changed. Researchers have recently proposed several probabilistic models that aim to capture how people do (or should) reason about counterfactuals. We present a new model and show that it accounts better for human inferences than several alternative models. Our model builds on the work of Pearl (2000), and extends his approach in a way that accommodates backtracking inferences and that acknowledges the difference between counterfactual interventions and counterfactual observations. We present 6 new experiments and analyze data from 4 experiments carried out by Rips (2010), and the results suggest that the new model provides an accurate account of both mean human judgments and the judgments of individuals.(PsycINFO Database Record (c) 2016 APA, all rights reserved)")


@article{abs-2401-06853,
  author       = {Siheng Xiong and
                  Ali Payani and
                  Ramana Kompella and
                  Faramarz Fekri},
  title        = {Large Language Models Can Learn Temporal Reasoning},
  journal      = {CoRR},
  volume       = {abs/2401.06853},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2401.06853},
    keywords = {
            Empirical Study,
            Temporal Reasoning,
            Other Model,
            Other Data Format
        },
}
@String(abs-2401-06853="While large language models (LLMs) have demonstrated remarkable reasoning capabilities, they are not without their flaws and inaccuracies. Recent studies have introduced various methods to mitigate these limitations. Temporal reasoning (TR), in particular, presents a significant challenge for LLMs due to its reliance on diverse temporal expressions and intricate contextual details. In this paper, we propose TG-LLM, a new framework towards language-based TR. To be specific, we first teach LLM to translate the context into a temporal graph (TG). A synthetic dataset, which is fully controllable and requires minimal supervision, is constructed for fine-tuning on this graph translation task. We confirm in experiments that the capability of TG extraction learned on our dataset can be transferred to other TR tasks and benchmarks. On top of that, we guide LLM to perform symbolic reasoning over the TG via Chain of Thoughts (CoTs) bootstrapping and special data augmentation strategies. We observe that CoTs with symbolic reasoning bring more consistent and reliable results than those using free-form text.")

@article{abs-2305-15541,
  author       = {Yuan Yang and
                  Siheng Xiong and
                  Ali Payani and
                  Ehsan Shareghi and
                  Faramarz Fekri},
  title        = {Harnessing the Power of Large Language Models for Natural Language
                  to First-Order Logic Translation},
  journal      = {CoRR},
  volume       = {abs/2305.15541},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.15541},
    keywords = {
            Method,
            Resource,
            First-Order Logic,
            Other Model,
            Other Data Format
        },
}
@String(abs-2305-15541="Translating natural language sentences to first-order logic (NL-FOL translation) is a longstanding challenge in the NLP and formal logic literature. This paper introduces LogicLLaMA, a LLaMA-7B model fine-tuned for NL-FOL translation using LoRA on a single GPU. LogicLLaMA is capable of directly translating natural language into FOL rules, which outperforms GPT-3.5. LogicLLaMA is also equipped to correct FOL rules predicted by GPT-3.5, and can achieve similar performance as GPT-4 with a fraction of the cost. This correction ability was achieved by a novel supervised fine-tuning (SFT) + reinforcement learning with human feedback (RLHF) framework, which initially trains on synthetically perturbed NL-FOL pairs to encourage chain-of-thought reasoning and then fine-tunes with RLHF on GPT-3.5 outputs using a FOL verifier as the reward model. To train LogicLLaMA, we present MALLS (large language Model generAted NL-FOL pairS), a dataset of 34K high-quality and diverse sentence-level NL-FOL pairs collected from GPT-4. The dataset was created by implementing a pipeline that prompts GPT-4 for pairs, and dynamically adjusts the prompts to ensure the collection of pairs with rich and diverse contexts at different levels of complexity, and verifies the validity of the generated FOL rules.")

@inproceedings{XiongYFK23,
  author       = {Siheng Xiong and
                  Yuan Yang and
                  Faramarz Fekri and
                  James Clayton Kerce},
  title        = {{TILP:} Differentiable Learning of Temporal Logical Rules on Knowledge
                  Graphs},
  booktitle    = {The Proceedings of ICLR},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=\_X12NmQKvX},
    keywords = {
            Method,
            Temporal Reasoning,
            Other Model,
            Other Data Format
        },
}
@String(XiongYFK23="Compared with static knowledge graphs, temporal knowledge graphs (tKG), which can capture the evolution and change of information over time, are more realistic and general. However, due to the complexity that the notion of time introduces to the learning of the rules, an accurate graph reasoning, e.g., predicting new links between entities, is still a difficult problem. In this paper, we propose TILP, a differentiable framework for temporal logical rules learning. By designing a constrained random walk mechanism and the introduction of temporal operators, we ensure the efficiency of our model. We present temporal features modeling in tKG, e.g., recurrence, temporal order, interval between pair of relations, and duration, and incorporate it into our learning process. We compare TILP with state-of-the-art methods on two benchmark datasets. We show that our proposed framework can improve upon the performance of baseline methods while providing interpretable results. In particular, we consider various scenarios in which training samples are limited, data is biased, and the time range between training and inference are different. In all these cases, TILP works much better than the state-of-the-art methods.")

@article{abs-2106-11417,
  author       = {Duo Xu and
                  Faramarz Fekri},
  title        = {Interpretable Model-based Hierarchical Reinforcement Learning using
                  Inductive Logic Programming},
  journal      = {CoRR},
  volume       = {abs/2106.11417},
  year         = {2021},
  url          = {https://arxiv.org/abs/2106.11417},
    keywords = {
            Method,
            Inductive Logic Programming,
            Other Model,
            Other Data Format
        },
}
@String(abs-2106-11417="Recently deep reinforcement learning has achieved tremendous success in wide ranges of applications. However, it notoriously lacks data-efficiency and interpretability. Data-efficiency is important as interacting with the environment is expensive. Further, interpretability can increase the transparency of the black-box-style deep RL models and hence gain trust from the users. In this work, we propose a new hierarchical framework via symbolic RL, leveraging a symbolic transition model to improve the data-efficiency and introduce the interpretability for learned policy. This framework consists of a high-level agent, a subtask solver and a symbolic transition model. Without assuming any prior knowledge on the state transition, we adopt inductive logic programming (ILP) to learn the rules of symbolic state transitions, introducing interpretability and making the learned behavior understandable to users. In empirical experiments, we confirmed that the proposed framework offers approximately between 30\% to 40\% more data efficiency over previous methods.")

@article{abs-1904-01554,
  author       = {Ali Payani and
                  Faramarz Fekri},
  title        = {Learning Algorithms via Neural Logic Networks},
  journal      = {CoRR},
  volume       = {abs/1904.01554},
  year         = {2019},
  url          = {http://arxiv.org/abs/1904.01554},
    keywords = {
            Method,
            Neural Logic Networks,
            Other Model,
            Other Data Format
        },
}
@String(abs-1904-01554="We propose a novel learning paradigm for Deep Neural Networks (DNN) by using Boolean logic algebra. We first present the basic differentiable operators of a Boolean system such as conjunction, disjunction and exclusive-OR and show how these elementary operators can be combined in a simple and meaningful way to form Neural Logic Networks (NLNs). We examine the effectiveness of the proposed NLN framework in learning Boolean functions and discrete-algorithmic tasks. We demonstrate that, in contrast to the implicit learning in MLP approach, the proposed neural logic networks can learn the logical functions explicitly that can be verified and interpreted by human. In particular, we propose a new framework for learning the inductive logic programming (ILP) problems by exploiting the explicit representational power of NLN. We show the proposed neural ILP solver is capable of feats such as predicate invention and recursion and can outperform the current state of the art neural ILP solvers using a variety of benchmark tasks such as decimal addition and multiplication, and sorting on ordered list.")








