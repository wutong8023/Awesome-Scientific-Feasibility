# Scientific Feasibility (SciFy) Literature 
This repository is maintained by [Tongtong Wu](https://wutong8023.site). Please don't hesitate to send me an email to collaborate or fix some entries (wutong8023 AT gmail.com). 
The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/rgscdxhxbwhp).

This page categorizes the literature by the **Foundation Model**.

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/foundation_model/README.md#hyperlink)
- [![](https://img.shields.io/badge/T5-1-blue)](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/foundation_model/README.md#t5)
- [![](https://img.shields.io/badge/Other_Model-19-blue)](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/foundation_model/README.md#other-model)
## Hyperlink 
 - [Overview](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/./)
 - [Application Area](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/application)
 - [Top Author](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/author)
 - [Contribution](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/contribution)
 - [Dataset Format](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/dataset)
 - [Foundation Model](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/foundation_model)
 - [Research Question](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/research_question)
 - [Published Time](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/time)
 - [Published Venue](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/SciFy4all/venue)

## T5

- [![](https://img.shields.io/badge/LOUHI@EACL-2021-blue)](https://www.aclweb.org/anthology/2021.louhi-1.11/) [**Scientific Claim Verification with VerT5erini**](https://www.aclweb.org/anthology/2021.louhi-1.11/) , <br> by *Ronak Pradeep and
Xueguang Ma and
Rodrigo Frassetto Nogueira and
Jimmy Lin* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L4-L9)<br> ```We propose a system called VerT5erini that exploits T5 for abstract retrieval, sentence selection, and label prediction, which are three critical sub-tasks of claim verification. We evaluate our pipeline on SciFACT, a newly curated dataset that requires models to not just predict the veracity of claims but also provide relevant sentences from a corpus of scientific literature that support the prediction. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```PradeepMNL21```<br>

## Other Model

- [![](https://img.shields.io/badge/EACL-2024-blue)](https://doi.org/10.48550/arXiv.2402.02844) [**Comparing Knowledge Sources for Open-Domain Scientific Claim Verification**](https://doi.org/10.48550/arXiv.2402.02844) , <br> by *Juraj Vladika and
Florian Matthes* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L195-L210)<br> ```We compare knowledge sources for open-domain scientific claim verification, a task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2402-02844```<br>

- [![](https://img.shields.io/badge/Findings_of_ACL-2023-blue)](https://doi.org/10.18653/v1/2023.findings-acl.387) [**Scientific Fact-Checking: A Survey of Resources and Approaches**](https://doi.org/10.18653/v1/2023.findings-acl.387) , <br> by *Juraj Vladika and
Florian Matthes* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L90-L105)<br> ```We present a survey of resources and approaches for scientific fact-checking, a task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```VladikaM23```<br>

- [![](https://img.shields.io/badge/Findings_of_EMNLP-2023-blue)](https://aclanthology.org/2023.findings-emnlp.416) [**Explainable Claim Verification via Knowledge-Grounded Reasoning with
Large Language Models**](https://aclanthology.org/2023.findings-emnlp.416) , <br> by *Haoran Wang and
Kai Shu* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L235-L251)<br> ```We propose a knowledge-grounded reasoning model for scientific claim verification that uses large language models to generate explanations for the predictions. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```WangS23a```<br>

- [![](https://img.shields.io/badge/CoRR-2023-blue)](https://doi.org/10.48550/arXiv.2310.09754) [**EX-FEVER: A Dataset for Multi-hop Explainable Fact Verification**](https://doi.org/10.48550/arXiv.2310.09754) , <br> by *Huanhuan Ma and
Weizhi Xu and
Yifan Wei and
Liuji Chen and
Liang Wang and
Qiang Liu and
Shu Wu and
Liang Wang* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L254-L275)<br> ```We present EX-FEVER, a new dataset for multi-hop explainable fact verification. EX-FEVER contains 10,000 claims and 100,000 abstracts from the research literature, and requires models to select abstracts containing evidence that SUPPORTS or REFUTES a given scientific claim. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2310-09754```<br>

- [![](https://img.shields.io/badge/EMNLP-2023-blue)](https://aclanthology.org/2023.emnlp-main.483) [**SCITAB: A Challenging Benchmark for Compositional Reasoning and
Claim Verification on Scientific Tables**](https://aclanthology.org/2023.emnlp-main.483) , <br> by *Xinyuan Lu and
Liangming Pan and
Qian Liu and
Preslav Nakov and
Min{-}Yen Kan* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L278-L297)<br> ```We present SCITAB, a new benchmark for compositional reasoning and claim verification on scientific tables. SCITAB contains 10,000 claims and 100,000 tables from the research literature, and requires models to select tables containing evidence that SUPPORTS or REFUTES a given scientific claim. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```LuPLNK23```<br>

- [![](https://img.shields.io/badge/CoRR-2023-blue)](https://doi.org/10.48550/arXiv.2305.11859) [**Complex Claim Verification with Evidence Retrieved in the Wild**](https://doi.org/10.48550/arXiv.2305.11859) , <br> by *Jifan Chen and
Grace Kim and
Aniruddh Sriram and
Greg Durrett and
Eunsol Choi* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L300-L318)<br> ```In this work, we present the first fully automated pipeline to check real-world claims by retrieving raw evidence from the web. We restrict our retriever to only search documents available prior to the claim's making, modeling the realistic scenario where an emerging claim needs to be checked. Our pipeline includes five components: claim decomposition, raw document retrieval, fine-grained evidence retrieval, claim-focused summarization, and veracity judgment.
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2305-11859```<br>

- [![](https://img.shields.io/badge/SIGIR-2023-blue)](https://doi.org/10.1145/3539618.3592049) [**Read it Twice: Towards Faithfully Interpretable Fact Verification
by Revisiting Evidence**](https://doi.org/10.1145/3539618.3592049) , <br> by *Xuming Hu and
Zhaochen Hong and
Zhijiang Guo and
Lijie Wen and
Philip S. Yu* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L321-L340)<br> ```In light of this, we propose a fact verification model named ReRead to retrieve evidence and verify claim that: (1) Train the evidence retriever to obtain interpretable evidence (i.e., faithfulness and plausibility criteria); (2) Train the claim verifier to revisit the evidence retrieved by the optimized evidence retriever to improve the accuracy. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```HuHGWY23```<br>

- [![](https://img.shields.io/badge/CoRR-2023-blue)](https://doi.org/10.48550/arXiv.2304.02769) [**Low-Shot Learning for Fictional Claim Verification**](https://doi.org/10.48550/arXiv.2304.02769) , <br> by *Viswanath Chadalapaka and
Derek Nguyen and
JoonWon Choi and
Shaunak Joshi and
Mohammad Rostami* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L343-L361)<br> ```We propose a low-shot learning model for fictional claim verification that uses a small number of examples to make predictions. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2304-02769```<br>

- [![](https://img.shields.io/badge/CoRR-2023-blue)](https://doi.org/10.48550/arXiv.2301.08914) [**ExClaim: Explainable Neural Claim Verification Using Rationalization**](https://doi.org/10.48550/arXiv.2301.08914) , <br> by *Sai Gurrapu and
Lifu Huang and
Feras A. Batarseh* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L386-L402)<br> ```We propose an explainable neural claim verification model that uses rationalization to generate explanations for the predictions. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2301-08914```<br>

- [![](https://img.shields.io/badge/SIGIR-2023-blue)](https://doi.org/10.1145/3539618.3591879) [**End-to-End Multimodal Fact-Checking and Explanation Generation: A
Challenging Dataset and Models**](https://doi.org/10.1145/3539618.3591879) , <br> by *Barry Menglong Yao and
Aditya Shah and
Lichao Sun and
Jin{-}Hee Cho and
Lifu Huang* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L405-L424)<br> ```We present a challenging dataset and models for end-to-end multimodal fact-checking and explanation generation. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```YaoS0CH23```<br>

- [![](https://img.shields.io/badge/Findings_of_NAACL-2022-blue)](https://doi.org/10.18653/v1/2022.findings-naacl.6) [**MultiVerS: Improving scientific claim verification with weak supervision
and full-document context**](https://doi.org/10.18653/v1/2022.findings-naacl.6) , <br> by *David Wadden and
Kyle Lo and
Lucy Lu Wang and
Arman Cohan and
Iz Beltagy and
Hannaneh Hajishirzi* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L48-L68)<br> ```We introduce MultiVerS, a weakly supervised model for scientific claim verification that leverages full-document context. We show that MultiVerS outperforms strong supervised baselines on the SciFact dataset, achieving state-of-the-art performance on this task. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```WaddenLWCBH22```<br>

- [![](https://img.shields.io/badge/Findings_of_EMNLP-2022-blue)](https://doi.org/10.18653/v1/2022.findings-emnlp.347) [**SciFact-Open: Towards open-domain scientific claim verification**](https://doi.org/10.18653/v1/2022.findings-emnlp.347) , <br> by *David Wadden and
Kyle Lo and
Bailey Kuehl and
Arman Cohan and
Iz Beltagy and
Lucy Lu Wang and
Hannaneh Hajishirzi* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L129-L149)<br> ```We introduce SciFact-Open, a new dataset for open-domain scientific claim verification. SciFact-Open contains 1,000 scientific claims and 10,000 abstracts from the research literature, and requires models to select abstracts containing evidence that SUPPORTS or REFUTES a given scientific claim. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```WaddenLKCBWH22```<br>

- [![](https://img.shields.io/badge/CoRR-2022-blue)](https://arxiv.org/abs/2202.02646) [**RerrFact: Reduced Evidence Retrieval Representations for Scientific
Claim Verification**](https://arxiv.org/abs/2202.02646) , <br> by *Ashish Rana and
Deepanshu Khanna and
Muskaan Singh and
Tirthankar Ghosal and
Harpreet Singh and
Prashant Singh Rana* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L152-L172)<br> ```We propose a reduced evidence retrieval model for scientific claim verification that uses a small number of retrieved abstracts to make predictions. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2202-02646```<br>

- [![](https://img.shields.io/badge/ACL-2022-blue)](https://doi.org/10.18653/v1/2022.acl-long.175) [**Generating Scientific Claims for Zero-Shot Scientific Fact Checking**](https://doi.org/10.18653/v1/2022.acl-long.175) , <br> by *Dustin Wright and
David Wadden and
Kyle Lo and
Bailey Kuehl and
Arman Cohan and
Isabelle Augenstein and
Lucy Lu Wang* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L213-L233)<br> </details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```0001WLKCAW22```<br>

- [![](https://img.shields.io/badge/CoRR-2021-blue)](https://arxiv.org/abs/2107.08188) [**Overview and Insights from the SciVer Shared Task on Scientific Claim
Verification**](https://arxiv.org/abs/2107.08188) , <br> by *David Wadden and
Kyle Lo* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L71-L87)<br> ```We present an overview of the SciVer shared task on scientific claim verification, which was held as part of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP). The shared task aimed to promote research on scientific claim verification, a new task that requires models to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2107-08188```<br>

- [![](https://img.shields.io/badge/EMNLP-2021-blue)](https://doi.org/10.18653/v1/2021.emnlp-main.290) [**Abstract, Rationale, Stance: A Joint Model for Scientific Claim
Verification**](https://doi.org/10.18653/v1/2021.emnlp-main.290) , <br> by *Zhiwei Zhang and
Jiyi Li and
Fumiyo Fukumoto and
Yanming Ye* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L108-L126)<br> ```We propose a joint model for scientific claim verification that predicts the stance of a given scientific claim by jointly learning to predict the abstract and rationale that support the stance. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```ZhangLFY21```<br>

- [![](https://img.shields.io/badge/CoRR-2021-blue)](https://arxiv.org/abs/2104.11572) [**QMUL-SDS at SCIVER: Step-by-Step Binary Classification for Scientific
Claim Verification**](https://arxiv.org/abs/2104.11572) , <br> by *Xia Zeng and
Arkaitz Zubiaga* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L175-L191)<br> ```We present a step-by-step binary classification model for scientific claim verification that predicts the stance of a given scientific claim by learning to predict the abstract and rationale that support the stance. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```abs-2104-11572```<br>

- [![](https://img.shields.io/badge/EMNLP-2020-blue)](https://doi.org/10.18653/v1/2020.emnlp-main.609) [**Fact or Fiction: Verifying Scientific Claims**](https://doi.org/10.18653/v1/2020.emnlp-main.609) , <br> by *David Wadden and
Shanchuan Lin and
Kyle Lo and
Lucy Lu Wang and
Madeleine van Zuylen and
Arman Cohan and
Hannaneh Hajishirzi* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L25-L45)<br> ```We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```WaddenLLWZCH20```<br>

- [![](https://img.shields.io/badge/ACL-2019-blue)](https://doi.org/10.18653/v1/p19-1244) [**Sentence-Level Evidence Embedding for Claim Verification with Hierarchical
Attention Networks**](https://doi.org/10.18653/v1/p19-1244) , <br> by *Jing Ma and
Wei Gao and
Shafiq R. Joty and
Kam{-}Fai Wong* [[bib]](https://github.com/wutong8023/Awesome-Scientific-Feasibility/blob/master/./bibtex.bib#L364-L383)<br> ```We propose a hierarchical attention network for scientific claim verification that uses sentence-level evidence embeddings to make predictions. 
```</details><details><summary><i class="fa-solid fa-bars"></i></summary><pre>```MaGJW19```<br>
